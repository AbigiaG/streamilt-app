# -*- coding: utf-8 -*-
"""Streamlit checkpoint 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ezKMSvrmlDEFITgIyk152UUayikiHJg8

#Financial Inclusion in Africa dataset

#Install the necessary packages
"""

import pandas as pd
import numpy as np

# Import the dataset
df = pd.read_csv('/content/Financial_inclusion_dataset.csv')

# Display the first few rows
print(df.head())

"""#Import you data and perform basic data exploration phase

Display general information about the dataset

Create a pandas profiling reports to gain insights into the dataset

Handle Missing and corrupted values

Remove duplicates, if they exist

Handle outliers, if they exist

Encode categorical features
"""

#Display general information about the dataset
# Basic statistics
print(df.describe())

# Information about the dataset
print(df.info())

#Create a pandas profiling reports to gain insights into the dataset
!pip install ydata-profiling --upgrade # Make sure you have the latest version
from ydata_profiling import ProfileReport
# Generate a profiling report
profile = ProfileReport(df, title="Pandas Profiling Report", explorative=True)
profile.to_notebook_iframe()

#Handle Missing and corrupted values
# Check for missing values
missing_values = df.isnull().sum()
print(missing_values)

# Filling numerical columns with median
numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns
for col in numerical_cols:
    df[col].fillna(df[col].median(), inplace=True)

#Filling categorical columns with mode
categorical_cols = df.select_dtypes(include=['object', 'category']).columns
for col in categorical_cols:
    df[col].fillna(df[col].mode()[0], inplace=True)

# Handling corrupted values
# Removing rows with impossible values
# Assuming 'age' cannot be negative
df = df[df['age_of_respondent'] >= 0]

#Remove duplicates, if they exist
# Check for duplicate rows
duplicate_rows = df.duplicated()
print(duplicate_rows.sum())

# Remove duplicate rows
df = df.drop_duplicates()

# Handle outliers, if they exist
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

#Using IQR to detect outliers for numerical columns
for col in numerical_cols:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    # Removing outliers
    df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]

# Alternatively, visualize using boxplots
for col in numerical_cols:
    plt.figure(figsize=(6,4))
    sns.boxplot(x=df[col])
    plt.title(f'Boxplot of {col}')
    plt.show()

#Encode categorical features
from sklearn.preprocessing import LabelEncoder, OneHotEncoder

# Label Encoding for binary categorical variables
le = LabelEncoder()
binary_cols = [col for col in categorical_cols if df[col].nunique() == 2]

for col in binary_cols:
    df[col] = le.fit_transform(df[col])

# One-Hot Encoding for multi-class categorical variables
multi_cat_cols = [col for col in categorical_cols if df[col].nunique() > 2]
df = pd.get_dummies(df, columns=multi_cat_cols, drop_first=True)

"""#Based on the previous data exploration train and test a machine learning classifier"""

# Import necessary libraries
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.preprocessing import LabelEncoder
import joblib

# Load the dataset
df = pd.read_csv('/content/Financial_inclusion_dataset.csv')

# Encode the target column 'bank_account'
df['bank_account'] = df['bank_account'].apply(lambda x: 1 if x == 'Yes' else 0)

# 1. Prepare data: Separate features (X) and target (y)
X = df.drop(columns=['bank_account', 'uniqueid', 'country'])  # Drop unique/non-informative columns
y = df['bank_account']  # Target column

# 2. Encode categorical features using Label Encoding
label_encoder = LabelEncoder()
for column in X.select_dtypes(include=['object']).columns:
    X[column] = label_encoder.fit_transform(X[column])

# 3. Split into training and test sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 4. Train a Random Forest Classifier
clf = RandomForestClassifier(random_state=42)
clf.fit(X_train, y_train)

# 5. Make predictions on the test set
y_pred = clf.predict(X_test)

# 6. Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

# Print evaluation metrics
print(f"Accuracy: {accuracy:.2f}")
print("Confusion Matrix:")
print(conf_matrix)
print("\nClassification Report:")
print(class_report)

# Save the model
joblib.dump(clf, 'model.pkl')

"""#Create a streamlit application (locally) and add input fields for your features and a validation button at the end of the form"""

pip install streamlit

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py

! wget -q -O - ipv4.icanhazip.com

! streamlit run app.py & npx localtunnel --port 8501

"""#Import your ML model into the streamlit application and start making predictions given the provided features values"""

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder

# Load trained model (assuming a pre-trained model is available)
# For demonstration, we're training a simple model in this code
def load_model():
    # Sample DataFrame to mock training (replace this with actual training data)
    data = {
        'location_type': ['Rural', 'Urban', 'Rural', 'Urban'],
        'cellphone_access': ['Yes', 'No', 'Yes', 'No'],
        'household_size': [3, 5, 2, 4],
        'age_of_respondent': [24, 70, 34, 26],
        'gender_of_respondent': ['Female', 'Male', 'Female', 'Male'],
        'relationship_with_head': ['Spouse', 'Head of Household', 'Child', 'Head of Household'],
        'marital_status': ['Married', 'Single', 'Widowed', 'Single'],
        'education_level': ['Primary', 'Secondary', 'No formal education', 'Vocational'],
        'job_type': ['Self employed', 'Government Dependent', 'Informally employed', 'Self employed'],
        'bank_account': [1, 0, 0, 1]  # Target
    }

    df = pd.DataFrame(data)

    # Encode categorical features
    label_encoder = LabelEncoder()
    for column in df.select_dtypes(include=['object']).columns:
        df[column] = label_encoder.fit_transform(df[column])

    X = df.drop(columns=['bank_account'])
    y = df['bank_account']

    # Train RandomForestClassifier for the sake of this demo
    clf = RandomForestClassifier(random_state=42)
    clf.fit(X, y)

    return clf, label_encoder, X.columns  # Returning model, label encoder, and feature names


# Load model and other components
clf, label_encoder, feature_columns = load_model()

# App title
st.title('Machine Learning Model for financial Inclusion Prediction')

st.write("""
### Predict whether an individual has a bank account based on their characteristics.
""")

# Create input fields for the features
location_type = st.selectbox("Location Type", ['Rural', 'Urban'])
cellphone_access = st.selectbox("Cellphone Access", ['Yes', 'No'])
household_size = st.slider("Household Size", min_value=1, max_value=20, value=3)
age_of_respondent = st.slider("Age of Respondent", min_value=16, max_value=100, value=30)
gender_of_respondent = st.selectbox("Gender", ['Female', 'Male'])
relationship_with_head = st.selectbox("Relationship with Head", ['Head of Household', 'Spouse', 'Child', 'Other relative'])
marital_status = st.selectbox("Marital Status", ['Married', 'Single', 'Widowed'])
education_level = st.selectbox("Education Level", ['No formal education', 'Primary', 'Secondary', 'Vocational/Specialized'])
job_type = st.selectbox("Job Type", ['Self employed', 'Government Dependent', 'Informally employed', 'Formally employed Private'])

# Create a button for prediction
if st.button("Predict"):
    # Prepare the input data in the right format
    input_data = pd.DataFrame({
        'location_type': [location_type],
        'cellphone_access': [cellphone_access],
        'household_size': [household_size],
        'age_of_respondent': [age_of_respondent],
        'gender_of_respondent': [gender_of_respondent],
        'relationship_with_head': [relationship_with_head],
        'marital_status': [marital_status],
        'education_level': [education_level],
        'job_type': [job_type]
    })

    # Encode categorical features using the trained LabelEncoder
    for column in input_data.select_dtypes(include=['object']).columns:
        input_data[column] = label_encoder.fit_transform(input_data[column])

    # Predict using the trained model
    prediction = clf.predict(input_data)[0]

    # Display the result
    if prediction == 1:
        st.success("The individual is predicted to have a bank account.")
    else:
        st.error("The individual is predicted to not have a bank account.")

